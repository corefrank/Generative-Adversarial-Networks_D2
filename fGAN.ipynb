{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmpHzu6_h30t",
        "outputId": "4087922d-635a-49c4-9f7d-b4dda150b018"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import trange\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "import time\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4TkF11luQ6h",
        "outputId": "ba6823a2-61dc-4c74-9b97-be680c0c064d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE8X3uAdud2W",
        "outputId": "81dd34b1-03ec-42bd-d17b-7d7eb76999fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utils.py', 'generate.py', 'data', 'checkpoints_kl', 'GAN_with_FID.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "path=\"/content/drive/MyDrive/DSLab2\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F7pOkMI4uAsa"
      },
      "outputs": [],
      "source": [
        "from utils import save_models, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SSal3hIQwFkR"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  def __init__(self, epochs=100, lr=0.0002, batch_size=64):\n",
        "    self.epochs=epochs\n",
        "    self.lr=lr\n",
        "    self.batch_size=batch_size\n",
        "\n",
        "\n",
        "def build_data_loader(batch_size):\n",
        "  # Data Pipeline\n",
        "  print('Dataset loading...')\n",
        "  # MNIST Dataset\n",
        "  transform = transforms.Compose([\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "  train_dataset = datasets.MNIST(root='data/MNIST/', train=True, transform=transform, download=True)\n",
        "  test_dataset = datasets.MNIST(root='data/MNIST/', train=False, transform=transform, download=False)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size, shuffle=False)\n",
        "  print('Dataset Loaded.')\n",
        "\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTVAFlDmNfg",
        "outputId": "b05cb0a1-1cbf-4ee2-d325-d387c3a340f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loading...\n",
            "Dataset Loaded.\n"
          ]
        }
      ],
      "source": [
        "args = Args()\n",
        "train_loader, test_loader = build_data_loader(args.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(100, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return self.fc4(x)\n",
        "        # return torch.sigmoid(self.fc4(x))"
      ],
      "metadata": {
        "id": "a1fDFvC9H9dW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# f-GAN\n",
        "\n"
      ],
      "metadata": {
        "id": "a3OnbeLNImU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class F_divergence:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "        if name == 'JS':\n",
        "            self.fdiv = lambda t: torch.log(torch.ones(t.shape, device=t.device) * 2) - torch.log(1 + torch.exp(-t))\n",
        "            self.fenchel = lambda t: -torch.log(2 - torch.exp(t))\n",
        "            self.threshold = 0\n",
        "\n",
        "        elif name == 'KL':\n",
        "            self.fdiv = lambda t: t\n",
        "            self.fenchel = lambda t: torch.exp(t - 1)\n",
        "            self.threshold = 1\n",
        "\n",
        "        elif name == 'RKL':\n",
        "            self.fdiv = lambda t: -torch.exp(-t)\n",
        "            self.fenchel = lambda t: -1 - torch.log(-t)\n",
        "            self.threshold = -1\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown divergence type: {name}\")\n",
        "\n",
        "    def activation(self, t):\n",
        "        return self.fdiv(t)\n",
        "\n",
        "    def f_star(self, t):\n",
        "        return self.fenchel(t)\n"
      ],
      "metadata": {
        "id": "h6dTB0SZK0zX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def D_train(x, G, D, D_optimizer, fdiv):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x, torch.ones(x.shape[0], 1)\n",
        "    x_real, y_real = x_real.cuda(), y_real.cuda()\n",
        "\n",
        "    D_real_output = fdiv.activation(D(x_real))\n",
        "    D_real_loss = torch.mean(D_real_output)\n",
        "\n",
        "    # train discriminator on facke\n",
        "    z = torch.randn(x.shape[0], 100).cuda()\n",
        "    x_fake, y_fake = G(z), torch.zeros(x.shape[0], 1).cuda()\n",
        "\n",
        "    D_fake_output = fdiv.activation(D(x_fake))\n",
        "    D_fake_loss = -torch.mean(fdiv.f_star(D_fake_output))\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    real_correct = (D_real_output >= fdiv.threshold).float().mean().item()\n",
        "    fake_correct = (D_fake_output < fdiv.threshold).float().mean().item()\n",
        "    D_accuracy = 0.5 * (real_correct + fake_correct)\n",
        "\n",
        "    (-D_loss).backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item(), D_accuracy\n",
        "\n",
        "\n",
        "def G_train(x, G, G_optimizer, fdiv):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = torch.randn(x.shape[0], 100).cuda()\n",
        "\n",
        "    G_output = fdiv.activation(G(z))\n",
        "    G_loss = torch.mean(fdiv.f_star(G_output))\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()\n"
      ],
      "metadata": {
        "id": "j8rNvK94JPtc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "OVr24CoxiGsW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q94qR3M7o8jo",
        "outputId": "0bdf96f6-9b13-45c8-b7be-c721bf249a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loading...\n",
            "Model loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Model\n",
        "print('Model Loading...')\n",
        "mnist_dim = 784\n",
        "G = torch.nn.DataParallel(Generator(g_output_dim = mnist_dim)).cuda()\n",
        "D = torch.nn.DataParallel(Discriminator(mnist_dim)).cuda()\n",
        "print('Model loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define f-divergence\n",
        "fdiv = F_divergence('KL')  # Choose the f-divergence type\n",
        "\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=args.lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=args.lr)\n",
        "\n",
        "# Lists to store loss and accuracy values for plotting\n",
        "D_losses = []\n",
        "G_losses = []\n",
        "D_accuracies = []\n",
        "\n",
        "# Training loop\n",
        "print('Start Training:')\n",
        "n_epoch = 10\n",
        "for epoch in trange(1, n_epoch + 1, leave=True):\n",
        "    D_epoch_loss = 0\n",
        "    G_epoch_loss = 0\n",
        "    D_epoch_accuracy = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        x = x.view(-1, mnist_dim)\n",
        "        G_loss = G_train(x, G, G_optimizer, fdiv)\n",
        "        D_loss, D_accuracy = D_train(x, G, D, D_optimizer, fdiv)\n",
        "\n",
        "        D_epoch_loss += D_loss\n",
        "        G_epoch_loss += G_loss\n",
        "        D_epoch_accuracy += D_accuracy\n",
        "        batch_count += 1\n",
        "\n",
        "    # Average the losses and accuracy for this epoch\n",
        "    D_losses.append(D_epoch_loss / batch_count)\n",
        "    G_losses.append(G_epoch_loss / batch_count)\n",
        "    D_accuracies.append(D_epoch_accuracy / batch_count)\n",
        "\n",
        "    # Save models periodically\n",
        "    if epoch % 10 == 0:\n",
        "        timestamp = time.time()\n",
        "        save_models(G, D, 'checkpoints_kl')\n",
        "\n",
        "print('Training done')\n",
        "\n",
        "print('D_losses:', D_losses)\n",
        "print('G_losses:', G_losses)\n",
        "print('D_accuracies:', D_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS5JA5-fiA3r",
        "outputId": "a796f879-00d0-4ef7-d55b-a76057ead98c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:58<00:00, 17.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done\n",
            "D_losses: [65.95773908721486, -885900.198186848, 108.68676505668331, 108.54585565026127, 108.79338639631455, 108.71101897103446, 108.58577578408378, 108.99024419235522, 109.39752266605271, 110.08816882135517]\n",
            "G_losses: [0.13871643422191332, 0.135336252433786, 0.1353356159889876, 0.13533542564174514, 0.1353353451151075, 0.13533530309637473, 0.13533528557400715, 0.13533527450139587, 0.1353352619354913, 0.1353352546278856]\n",
            "D_accuracies: [0.777393723347548, 0.8755996801705757, 0.6803787979744137, 0.6803371535181236, 0.6803954557569296, 0.6803538113006397, 0.6803454824093816, 0.6803621401918977, 0.6803954557569296, 0.6804537579957356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate"
      ],
      "metadata": {
        "id": "9D0cw-Kgh8Ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjTvzBMFve-3",
        "outputId": "0d70f54b-3de2-4be4-d727-86837f3214b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loading...\n",
            "Model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/DSLab2/utils.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(os.path.join(folder,'G.pth'))\n"
          ]
        }
      ],
      "source": [
        "# Load Model\n",
        "print('Model Loading...')\n",
        "model = Generator(g_output_dim=mnist_dim).cuda()\n",
        "model = load_model(model, 'checkpoints_js')\n",
        "model = torch.nn.DataParallel(model).cuda()\n",
        "model.eval()\n",
        "print('Model loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T1BMnNnv-t0"
      },
      "outputs": [],
      "source": [
        "# Gernerate Samples\n",
        "sample_path = 'samples_f'\n",
        "os.makedirs(sample_path, exist_ok=True)\n",
        "\n",
        "n_samples = 0\n",
        "with torch.no_grad():\n",
        "    while n_samples<10000:\n",
        "        z = torch.randn(args.batch_size, 100).cuda()\n",
        "        x = model(z)\n",
        "        x = x.reshape(args.batch_size, 28, 28)\n",
        "        for k in range(x.shape[0]):\n",
        "            if n_samples<10000:\n",
        "                torchvision.utils.save_image(x[k:k+1], os.path.join(sample_path, f'{n_samples}.png'))\n",
        "                n_samples += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}